{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b7a0e6-8d29-4e68-b22f-dc0aeb1090db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, jit, int64\n",
    "import numpy as np\n",
    "import timeit, random, time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28646985-fe44-4812-811d-e28015c119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen_matrix = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "blur_matrix = np.array([\n",
    "    [0.0625, 0.125, 0.0625],\n",
    "    [0.125, 0.25, 0.125],\n",
    "    [0.0625, 0.125, 0.0625]\n",
    "])\n",
    "\n",
    "outline_matrix = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, 8, -1],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b30d021-8f25-46af-956d-4c7846ff3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target_size(img_size, kernel_size):\n",
    "    width = img_size[0] - kernel_size[0] + 1\n",
    "    height = img_size[1] - kernel_size[1] + 1\n",
    "    return (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c9f650-307d-46a4-9b7f-1e7817ee93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_convolve_runner(img, kernel):\n",
    "    # Generate the output array like before\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape,\n",
    "        kernel_size=kernel.shape\n",
    "    )\n",
    "    convolved_img = np.zeros(shape=tgt_size)\n",
    "    \n",
    "    # The maximum number of threads per block is 1024, so the maximum would be 32 by 32. We use 16 by 16 here because why not :D\n",
    "    blockDim = (16, 16)\n",
    "    \n",
    "    # This will determine the number of blocks needed and the dimension of the grid\n",
    "    gridDim = (tgt_size[0] // blockDim[0] + 1, tgt_size[1] // blockDim[1] + 1)\n",
    "    \n",
    "    # Calling the GPU function. This will run the gpu_convolve function on every single thread in every block, and each thread will perform one singular convolution.\n",
    "    gpu_convolve[gridDim, blockDim](np.array(img), kernel, convolved_img)\n",
    "    \n",
    "    return convolved_img\n",
    "    \n",
    "\n",
    "@cuda.jit\n",
    "def gpu_convolve(image, mask, result):\n",
    "    # cuda.gird(2) will return the absolute position of the thread in the entire grid. The 2 is the number of dimensions. Essentially, this is \n",
    "    # cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x but in a single function.\n",
    "    i, j = cuda.grid(2)\n",
    "    \n",
    "    # If i or j are outside of the bounds, return. This is because the largest i and j will always be a multiple of 16 (the block dimensions)\n",
    "    image_rows, image_cols = result.shape\n",
    "    if (i >= image_rows) or (j >= image_cols): \n",
    "        return\n",
    "    \n",
    "    # Set initial sum to 0\n",
    "    s = 0\n",
    "    \n",
    "    # Create the sub-array\n",
    "    kx = mask.shape[0]\n",
    "    ky = mask.shape[1]\n",
    "    mat = image[i:i+kx, j:j+ky]\n",
    "    \n",
    "    # Calculate the sum\n",
    "    for k in range(mat.shape[0]):\n",
    "        for l in range(mat.shape[1]):\n",
    "            s += mat[k, l] * mask[k, l]\n",
    "\n",
    "    result[i, j] = max(0, s) # relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f922de-984d-4437-8c5d-1a12b239ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def gpu_maxpool_runner(img, dim):\n",
    "    size_x = ceil(img.shape[0] / dim[0])\n",
    "    size_y = ceil(img.shape[1] / dim[1])\n",
    "    \n",
    "    result = np.zeros(shape=(size_x, size_y))\n",
    "    \n",
    "    blockDim = (16, 16)\n",
    "    gridDim = (size_x // blockDim[0] + 1, size_y // blockDim[1] + 1)\n",
    "    \n",
    "    gpu_maxpool[gridDim, blockDim](np.array(img), np.array(dim), result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@cuda.jit\n",
    "def gpu_maxpool(img, dim, res):\n",
    "    i, j = cuda.grid(2)\n",
    "        \n",
    "    if (i >= res.shape[0]) or (j >= res.shape[1]): \n",
    "        return\n",
    "        \n",
    "    maxpool = -999\n",
    "    \n",
    "    for k in range(dim[0]):\n",
    "        for l in range(dim[1]):\n",
    "            if dim[0]*i+k < img.shape[0] and dim[1]*j+l < img.shape[1]:\n",
    "                maxpool = max(img[dim[0]*i+k][dim[1]*j+l], maxpool)\n",
    "            else:\n",
    "                maxpool = max(0, maxpool)\n",
    "\n",
    "    res[i][j] = maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d626d85-72e0-4960-a751-73ebec95f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5902ca27-59d3-43ea-ac79-89254414406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[0:10000]\n",
    "y_train = y_train[0:10000]\n",
    "x_test = x_test[0:2000]\n",
    "y_test = y_test[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f029540a-0272-4ca3-b9a9-b47e7990f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(img):\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = gpu_convolve_runner(img, outline_matrix)\n",
    "    img = gpu_maxpool_runner(img, (2, 2))\n",
    "    img = gpu_convolve_runner(img, sharpen_matrix)\n",
    "    img = gpu_maxpool_runner(img, (2, 2))\n",
    "    return img\n",
    "\n",
    "def flatten(img):\n",
    "    img = np.reshape(img, 36)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8169c756-df47-487b-93c2-32dc44f16085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3647ca90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = x_train[5]\n",
    "plt.imshow(test_img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a7ae10-ffc7-4ff4-864b-fa13cfe1c9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f326f5a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img_final = preprocess_pipeline(np.array(test_img))\n",
    "plt.imshow(test_img_final, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ee24d0-2c62-42b1-8c5f-b9f2e296e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  8.94509769,  0.01960885,\n",
       "        0.        ,  0.        , 10.58039154,  5.89019635,  6.02352937,\n",
       "        6.86274488,  0.        ,  0.        ,  1.97647172,  8.43921534,\n",
       "        4.28235292,  7.79215674,  0.        ,  0.        , 10.13333362,\n",
       "       10.11764675,  7.26666635,  8.65882323, 18.87843148, 10.72941216,\n",
       "        9.86274501, 10.14509797,  0.        ,  3.36862797,  3.28235334,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(test_img_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89df1ba8-8e41-4577-8d1b-63a8cc1c1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_processed = []\n",
    "for x in x_train:\n",
    "    new = flatten(preprocess_pipeline(x))\n",
    "    x_train_processed.append(new)\n",
    "x_train_processed = np.array(x_train_processed)\n",
    "\n",
    "x_test_processed = []\n",
    "for x in x_test:\n",
    "    new = flatten(preprocess_pipeline(x))\n",
    "    x_test_processed.append(new)\n",
    "x_test_processed = np.array(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "258f297d-0b25-4bb2-b35d-4f1e01b01069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fbac26-4938-4e6b-9c06-4c5c0c5c8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, input_shape=(36,), activation=\"sigmoid\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "y_train_category = to_categorical(y_train, 10)\n",
    "y_test_category = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2658659-c7a4-49bd-90b4-15065f8a77ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - 8s 17ms/step - loss: 2.1890 - accuracy: 0.2364\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 1.7426 - accuracy: 0.4768\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 1.3044 - accuracy: 0.6307\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 1.0514 - accuracy: 0.6974\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.9189 - accuracy: 0.7278\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.8422 - accuracy: 0.7452\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.7953 - accuracy: 0.7544\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.7622 - accuracy: 0.7624\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.7368 - accuracy: 0.7694\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.7157 - accuracy: 0.7782\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6981 - accuracy: 0.7833\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6817 - accuracy: 0.7889\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6678 - accuracy: 0.7922\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6560 - accuracy: 0.7958\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6430 - accuracy: 0.8029\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.6329 - accuracy: 0.8012\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.6217 - accuracy: 0.8081\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.6113 - accuracy: 0.8117\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.81 - 1s 16ms/step - loss: 0.6030 - accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5952 - accuracy: 0.8147\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5866 - accuracy: 0.8162\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5782 - accuracy: 0.8186\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5707 - accuracy: 0.8223\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5624 - accuracy: 0.8244\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.5570 - accuracy: 0.8279\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5495 - accuracy: 0.8277\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5419 - accuracy: 0.8290\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.5355 - accuracy: 0.8303\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5304 - accuracy: 0.8343\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5236 - accuracy: 0.8340\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5199 - accuracy: 0.8369\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5148 - accuracy: 0.8381\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.5077 - accuracy: 0.8398\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.5032 - accuracy: 0.8394\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4967 - accuracy: 0.8443\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4942 - accuracy: 0.8446\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4881 - accuracy: 0.8457\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.4840 - accuracy: 0.8465\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4787 - accuracy: 0.8487\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4793 - accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4716 - accuracy: 0.8491\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4681 - accuracy: 0.8518\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4620 - accuracy: 0.8513\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4586 - accuracy: 0.8526\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4556 - accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4499 - accuracy: 0.8542\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4475 - accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4434 - accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4418 - accuracy: 0.8566\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4381 - accuracy: 0.8584\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4333 - accuracy: 0.8620\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4309 - accuracy: 0.8602\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4279 - accuracy: 0.8618\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4270 - accuracy: 0.8598\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4220 - accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4199 - accuracy: 0.8645\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4198 - accuracy: 0.8632\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4150 - accuracy: 0.8645\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4128 - accuracy: 0.8644\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4101 - accuracy: 0.8669\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.4092 - accuracy: 0.8634\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4042 - accuracy: 0.8672\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.4026 - accuracy: 0.8675\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 1s 15ms/step - loss: 0.4001 - accuracy: 0.8694\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3995 - accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3968 - accuracy: 0.8723\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3961 - accuracy: 0.8707\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3935 - accuracy: 0.8737\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3903 - accuracy: 0.8734\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3890 - accuracy: 0.8746\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3876 - accuracy: 0.8737\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3871 - accuracy: 0.8724\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3848 - accuracy: 0.8739\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3819 - accuracy: 0.8762\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3830 - accuracy: 0.8731\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3793 - accuracy: 0.8754\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.87 - 1s 16ms/step - loss: 0.3763 - accuracy: 0.8769\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3778 - accuracy: 0.8789\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 1s 18ms/step - loss: 0.3753 - accuracy: 0.8763\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3725 - accuracy: 0.8800\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3709 - accuracy: 0.8782\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3727 - accuracy: 0.8760\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3696 - accuracy: 0.8785\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3686 - accuracy: 0.8787\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3675 - accuracy: 0.8779\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3659 - accuracy: 0.8802\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3648 - accuracy: 0.8796\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3616 - accuracy: 0.8817\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3624 - accuracy: 0.8816\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3619 - accuracy: 0.8818\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3597 - accuracy: 0.8824\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3592 - accuracy: 0.8814\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3571 - accuracy: 0.8819\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3565 - accuracy: 0.8839\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3557 - accuracy: 0.8840\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3546 - accuracy: 0.8875\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3522 - accuracy: 0.8858\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3510 - accuracy: 0.8857\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.3523 - accuracy: 0.8845\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 1s 16ms/step - loss: 0.3515 - accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(0.1)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "H = model.fit(x_train_processed, y_train_category, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac20a579-5d98-4dc9-8fbf-86fc04d505ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6708 - accuracy: 0.7945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6707645654678345, 0.7944999933242798]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_processed, y_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4b869-874f-46b4-b63d-81a66f0bda66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
